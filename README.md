# Heart Attack Prediction Using ECG and PPG Datasets

A comprehensive machine learning and deep learning pipeline for predicting heart attacks using ECG (Electrocardiogram) and PPG (Photoplethysmogram) physiological signals.

## ğŸ“Š Project Overview

This project implements a complete research-grade pipeline that progresses from basic preprocessing and exploratory data analysis through traditional ML models to advanced deep learning architectures, with extensive model comparison and interpretability analysis.

### Datasets
- **ECG**: 4,997 samples Ã— 141 features (time-series signal data)
- **PPG**: 2,576 samples Ã— 2,001 features (time-series signal data)

## ğŸš€ Features

### Data Preprocessing
- Signal filtering (Butterworth, Savitzky-Golay)
- Noise removal and baseline wander correction
- Normalization (z-score, min-max, robust scaling)
- Outlier detection and handling (IQR, isolation forest)
- Missing value imputation
- Class imbalance handling (SMOTE, ADASYN)

### Feature Extraction
- **Time-domain features**: Statistical, peak detection, morphological
- **Frequency-domain features**: FFT, PSD, spectral analysis
- **Wavelet features**: DWT, wavelet energy, wavelet entropy
- **HRV features**: Time-domain, frequency-domain, and non-linear HRV metrics

### Machine Learning Models
- Logistic Regression
- Decision Tree
- Random Forest
- Support Vector Machine (SVM)
- K-Nearest Neighbors (KNN)
- XGBoost
- LightGBM
- CatBoost

### Deep Learning Models
- Multi-Layer Perceptron (MLP)
- 1D Convolutional Neural Networks (CNN)
- Long Short-Term Memory (LSTM)
- Gated Recurrent Units (GRU)

### Evaluation & Analysis
- Comprehensive metrics (Accuracy, Precision, Recall, F1, ROC-AUC, MCC, Kappa)
- Cross-validation
- Model comparison and ranking
- Statistical significance testing

## ğŸ“ Project Structure

```
ecg_ppg_paper/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ processed/              # Preprocessed data
â”‚   â””â”€â”€ features/               # Extracted features
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing/          # Data loading and preprocessing
â”‚   â”‚   â”œâ”€â”€ data_loader.py
â”‚   â”‚   â”œâ”€â”€ signal_processing.py
â”‚   â”‚   â””â”€â”€ data_splitting.py
â”‚   â”œâ”€â”€ features/               # Feature extraction
â”‚   â”‚   â”œâ”€â”€ time_domain.py
â”‚   â”‚   â”œâ”€â”€ frequency_domain.py
â”‚   â”‚   â”œâ”€â”€ wavelet_features.py
â”‚   â”‚   â””â”€â”€ hrv_features.py
â”‚   â”œâ”€â”€ models/                 # Model implementations
â”‚   â”‚   â”œâ”€â”€ traditional_ml.py
â”‚   â”‚   â””â”€â”€ deep_learning.py
â”‚   â”œâ”€â”€ evaluation/             # Evaluation utilities
â”‚   â”‚   â”œâ”€â”€ metrics.py
â”‚   â”‚   â””â”€â”€ comparison.py
â”‚   â””â”€â”€ visualization/          # Visualization tools
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                # Generated plots
â”‚   â”œâ”€â”€ models/                 # Saved models
â”‚   â””â”€â”€ reports/                # Analysis reports
â”œâ”€â”€ main_pipeline.py            # Main pipeline script
â”œâ”€â”€ config.yaml                 # Configuration file
â”œâ”€â”€ requirements.txt            # Python dependencies
â””â”€â”€ README.md                   # This file
```

## ğŸ› ï¸ Installation

### Prerequisites
- Python 3.8 or higher
- CUDA-capable GPU (optional, for deep learning acceleration)

### Setup

1. **Clone the repository**
```bash
git clone <repository-url>
cd ecg_ppg_paper
```

2. **Create a virtual environment** (recommended)
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

## ğŸ“– Usage

### Quick Start

Run the complete pipeline on ECG dataset:
```bash
python main_pipeline.py --dataset ecg
```

Run on PPG dataset:
```bash
python main_pipeline.py --dataset ppg
```

Run on both datasets:
```bash
python main_pipeline.py --dataset both
```

### Quick Test Mode

For rapid testing with reduced hyperparameter grids:
```bash
python main_pipeline.py --dataset ecg --quick-test
```

### Configuration

Edit `config.yaml` to customize:
- Data paths
- Preprocessing parameters
- Feature extraction settings
- Model hyperparameters
- Training configurations

### Individual Module Usage

**Load and preprocess data:**
```python
from src.preprocessing.data_loader import load_datasets
from src.preprocessing.signal_processing import preprocess_pipeline

datasets = load_datasets()
ecg_df, ppg_df = datasets['ecg'], datasets['ppg']
```

**Extract features:**
```python
from src.features.time_domain import extract_time_features_from_dataframe
from src.features.frequency_domain import extract_frequency_features_from_dataframe

time_features = extract_time_features_from_dataframe(ecg_df)
freq_features = extract_frequency_features_from_dataframe(ecg_df)
```

**Train models:**
```python
from src.models.traditional_ml import train_random_forest
from src.models.deep_learning import train_deep_learning_model, MLPClassifier

# Traditional ML
model, metrics = train_random_forest(X_train, y_train, X_val, y_val)

# Deep Learning
mlp = MLPClassifier(input_dim=100, num_classes=2)
trained_model, metrics = train_deep_learning_model(mlp, X_train, y_train, X_val, y_val)
```

**Evaluate and compare:**
```python
from src.evaluation.metrics import evaluate_model
from src.evaluation.comparison import compare_models

results = evaluate_model(model, X_test, y_test)
comparison_df = compare_models(all_results)
```

## ğŸ“Š Results

After running the pipeline, results will be saved in:
- `results/models/`: Trained model files
- `results/reports/`: Model comparison tables and metrics
- `results/figures/`: Visualization plots

### Expected Performance
- All models should achieve >70% accuracy (baseline)
- Deep learning models typically outperform traditional ML
- Ensemble models (XGBoost, LightGBM, CatBoost) show strong performance
- Best models typically achieve 85-95% accuracy depending on dataset

## ğŸ”§ Advanced Configuration

### Hyperparameter Tuning

Modify `config.yaml` to adjust hyperparameter search spaces:

```yaml
ml_models:
  random_forest:
    enabled: true
    n_estimators: [50, 100, 200]
    max_depth: [10, 20, 30]
    min_samples_split: [2, 5]
```

### Feature Selection

Enable/disable feature types in `config.yaml`:

```yaml
features:
  time_domain: true
  frequency_domain: true
  wavelet: true
  hrv: true  # ECG only
```

### Class Imbalance Handling

Choose resampling strategy:

```yaml
imbalance:
  method: "smote"  # Options: smote, adasyn, class_weights, none
  sampling_strategy: "auto"
```

## ğŸ“ˆ Performance Benchmarks

Approximate execution times (with GPU):
- **Preprocessing**: < 2 minutes
- **Feature extraction**: < 5 minutes
- **Traditional ML training**: 1-5 minutes per model
- **Deep learning training**: 10-30 minutes per model
- **Full pipeline**: 1-4 hours (depending on configuration)

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

## ğŸ“ License

This project is licensed under the MIT License - see the LICENSE file for details.

## ğŸ“§ Contact

For questions or feedback, please open an issue on GitHub.

## ğŸ™ Acknowledgments

- ECG and PPG datasets from [source]
- Built with scikit-learn, PyTorch, XGBoost, and other open-source libraries

## ğŸ“š Citation

If you use this code in your research, please cite:

```bibtex
@software{heart_attack_prediction,
  title={Heart Attack Prediction Using ECG and PPG Datasets},
  author={Your Name},
  year={2026},
  url={https://github.com/yourusername/ecg_ppg_paper}
}
```

## ğŸ”¬ Research Applications

This pipeline can be used for:
- Cardiovascular disease prediction research
- Signal processing algorithm development
- Machine learning model benchmarking
- Feature engineering studies
- Deep learning architecture comparison

## ğŸ› Troubleshooting

### Common Issues

**CUDA out of memory:**
- Reduce batch size in `config.yaml`
- Use CPU instead: Set `device='cpu'` in deep learning training

**Missing dependencies:**
```bash
pip install --upgrade -r requirements.txt
```

**Data loading errors:**
- Verify dataset paths in `config.yaml`
- Ensure CSV files are in the correct format

## ğŸ“Š Visualization

The pipeline generates various visualizations:
- Signal waveforms
- Feature distributions
- Correlation heatmaps
- ROC curves
- Confusion matrices
- Model comparison charts

## ğŸ¯ Future Enhancements

- [ ] Add more deep learning architectures (Transformers, ResNet)
- [ ] Implement SHAP and LIME interpretability
- [ ] Add real-time prediction API
- [ ] Create interactive dashboard
- [ ] Add more visualization options
- [ ] Implement ensemble learning strategies
- [ ] Add support for more datasets
